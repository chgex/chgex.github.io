---
layout: post
title: Multi-scale context aggregation by dilated convolutions
date: 2021-03-24
Author: JIUGE 
tags: [论文阅读]
comments: true
toc: false
---

这篇论文发表于2016年，者提出了一种专门针对密集型预测的卷积网络结构：这种结构使用了空洞卷积，在不损失像素分辨率和覆盖范围的情况下，扩展卷积的感受野，系统性的聚集多尺度上下文信息。

<!-- more -->

# 论文简读：Multi-scale context aggregation by dilated convolutions

论文信息：

<img src="https://gitee.com/changyv/md-pic/raw/master/20210324221215.png" alt="image-20210324221213524" style="zoom:75%;" />

发表时间：2016年，于ICLR

## Abstract

卷积网络最初是被用来进行图像分类的，但基于卷积网络的语义分割模型，也有着不错的效果。语义分割是密集预测型问题，基于这一点，作者提出了一种专门针对密集型预测的卷积网络结构：这种结构使用空洞卷积，在不损失像素分辨率和覆盖范围的情况下，扩展卷积的感受野，系统性的聚集多尺度上下文信息。

## 1 Introduction

语义分割(semantic segmentation)要求将每个像素分类到给定的一组类别中，这需要将像素级别的准确性和多尺度上下文推理两者相结合。

目前的图像分类网络通过一系列池化层和下采样层来获得全局预测，但下采样层会损失图像的分辨率。而密集型预测则需要结合上下文推理和全像素输出，最近有两种方法来处理这一情况：

+ 引入多个上卷积层(up-convolution)，从全局视角，恢复损失的像素。

  > 像素是在像采样层损失的。

+ 将输入图像的多个不同尺寸的缩放版本，作为网络的输入，再将多个预测进行组合。

作者提出了一种卷积网络模块，该模块基于空洞卷积（dilated convolations），可以聚合多尺度上下文信息，而不会丢失像素，也不用分析重新缩放的图像。可以直接加入到网络结构中。

作者通过实验证明，将该模块加入到现有的语义分割网络中，能够提升模型的准确性。

## 2 Dilated Convolutions

<img src="https://gitee.com/changyv/md-pic/raw/master/20210324200910.png" alt="image-20210324200900278" style="zoom:75%;" />

作者指出，随着空洞卷积的层数增加，感受野大小呈现指数式增长。

## 3 Multi-scale Context Aggregation

作者提出的空洞卷积模块，输入为C个特征图，输出也为C个图征图，输入和输出具有相同的形式。因此，该模块可以被插入到任何密集型预测网络中。

作者从上下文模型的基本形式开始，在基本新式中，每层有C个通道，模型内没有使用正则化，也没有定义损失。基本新式的模型有7层，每层使用3\*3的空洞卷积。模型的具体参数见下图：

<img src="https://gitee.com/changyv/md-pic/raw/master/20210324205717.png" alt="image-20210324205716322" style="zoom:75%;" />

+ 第一层和第二层使用3\*3\*C的空洞卷积，

+ 每一层后面跟随一个逐点截断(pointwise trunction)函数：$max(.,0)$ , 
+ 最后一层使用1\*1\*C的卷积，并产生输出。
+ 实验中，模块的输入是64\*64分辨率的特征图，由前模块(front end)提供，详见下文。
+ 第六层之后，感受野不再扩张。

作者在实验中发现，标准的随机初始化对于对于上下文模块没有效果，于是提出了以下初始化方法：
$$
K^b (t,a)=1_{[t=0]}1_{[a=b]}
$$

> a是输入特征图的索引，
>
> b是输出特征图的索引，

这样的初始化设置，能让每层，将输入直接传递给下一层。

作者的实验表明，上述这个基本模块，能够提升网络的正确率，而且参数很少：只有大约$64C^2$ 个。

作者还训练了一个更大型的网络，使用以下初始化方式，以解决不同层的特征图的差异：
$$
K^b(t,a)=
\begin{cases}
\frac{C}{c_i +1} \space t=0\space  and \space \lfloor\frac{aC}{c_i}\rfloor=\lfloor\frac{bC}{c_{i+1}}\rfloor
\\
\epsilon  \space  otherwise
\end{cases}
$$


## 4 Front End

作者提出并训练了一个front-end模型，该模块接受彩色图像作为输入，输出通道数C=21的特征图，使用填充元素为0的填充策略。

该模型基于VGG-16网络，但去除了最后两个池化层。去除了整个网络的stride，取而代之的是dilation factor=2。还去除了网络中间层的填充。

该front-end模型是在Pascal VOC 2012训练集上训练，使用随机梯度下降(stochastic gradient sdescent, SGD)，mini-batch=14，学习率为0.001，momentum为0.9，迭代次数为60K。最后的结果是优于FCN-8s, Deeplab,DeepLab-Msc等网络的。 下图是其效果：

<img src="https://gitee.com/changyv/md-pic/raw/master/20210324215348.png" alt="image-20210324215346698" style="zoom:65%;" />

## 5 Experiments

接下来，作者在COCO数据集上训练了该front-end模型，并取得了不错的表现（计算IOU，以衡量模型）。作者将这归于“去除了用于图像分类的残留部分”。

然后，作者将两个上下文模块（一个基本模块，一个大模块）加入到front-end网络中，由于空洞卷积模块的感受野是67\*67，所以使用了宽度为33的0元素填充。

实验结果显示，使用了大上下文模块的网络有很好的性能表现。见下图：

<img src="https://gitee.com/changyv/md-pic/raw/master/20210324220620.png" alt="image-20210324220619071" style="zoom:55%;" />

以上。