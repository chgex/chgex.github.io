---
layout: post
title: RCNN系列总结
date: 2021-07-08
Author: chge 
tags: [论文阅读]
comments: true
toc: false
---

RCNN系列总结。

<!-- more -->

# RCNN系列总结

从RCNN到Faster RCNN，做一个简短的总结。

## 1 R-CNN (region with cnn feature)

RCNN是使用深度学习进行目标检测的开篇之作，作者Ross Girshick多次在PASCAL VOC的目标检测竞赛中取得第一名。

RCNN算法流程如下：

1.对于输入的图片，使用选择性搜索算法，得到大约2K的候选区域（框）；

2.对每个候选区域，放到深度神经网络 (CNNs) 提取特征；

+ 候选框的大小是不固定的，所以在送入卷积神经网络之前，会先将候选区域缩放到227×227大小。

+ 经过CNNs提取特征后，输出这个候选区域的特征向量，该特征向量为4096维。

+ 于是，对整张图来说，经过CNNs特征提取，得到2000×4096的特征矩阵。

3.将提取出来的特征，送入20个SVM分类器（因为PASCAL VOC数据集共有20个类，所以有20个SVM分类器），判断属于该类的概率；

+ SVM分类器权值维度为4096×20；

+ 将2000×4096维的特征矩阵与20个SVM组成的权值矩阵相乘，得到2000×20的概率矩阵（2000是图片的候选区域个数，20是类别数）；

  > 2000×20的概率矩阵，每一行表示这个候选区域，属于每个目标类别的概率；

+ 对2000×20的概率矩阵，根据概率得分，对每一类进行非极大值抑制 (NMS)，得到该类的得分最高的一些候选区域（即对列进行NMS）。

  > 非极大值抑制算法中，使用IoU来作为两个框的重复度指标。

4.使用回归器，修正候选框的位置（选择性搜索算产生的候选框准确性不高，所以需要修正）。

存在的问题：

+ 检测速度极慢（论文中，53s一张）；
+ 模块独立，所以是单独训练的；
+ 训练所需空间大。

## 2 Fast-RCNN

作者是同一人，还是Ross Girshick。使用VGG16作为backbone（骨干网），要比RCNN速度更快，推理时间更短，在PASCAL VOC上，准确率为66%。

<img src="__md__/image-20210708163829225.png" alt="image-20210708163829225" style="zoom:75%;" />

Fast Rcnn算法流程：

1.同样使用选择性搜索算法，得到2K个候选区域；

2.将图像输入到CNNs，得到整张图片的特征图，然后将选择性搜索算法得到的候选区域坐标，投影到特征图上，得到候选区域对应的特征图；

> RCNN是将每个候选区域，输入到CNNs，得到每个区域的特征向量，这样会出现大量的重复区域的特征图提取，而Fast RCNN直接将整张图输入到CNNs提取特征，然后根据选择性搜索算法得到的区域坐标，在特征图中，获取该推荐区域的特征向量。
>
> 映射过程和获取区域的特征向量这一块，由RoI Projection来完成。

3.将每个候选区域的特征图，通过RoI Poling层，缩放到7×7大小；

4.将这些7×7大小的特征图，通过一系列全连接层，最后得到分类结果和边界框预测。

> 在RCNN中，作者专门训练了SVM分类器和回归器，但在Fast RCNN中，作者将分类和回归都结合在一个网络中了。

### 分类器和回归器

分类器：输出N+1个类别的概率（N=20，1=背景）,

回归器：输出对应N+1个类别的候选边界框回归参数$(d_x,d_y,d_w,d_h)$，共 $(N+1) × 4$ 个结点。

## 3 Faster RCNN

作者同样是Ross Girshick，同样使用VGG16作为骨干网，推理速度进一步提升，在2015年的ILSVRC和COCO竞赛中，取得多个第一。  

Faster RCNN算法流程：

1.将图像整个输入网络得到对应的特征图；

2.使用RPN结构生成候选框，将RPN生成的候选框投影到特征图上，获得相应的特征矩阵；

3.特征矩阵经过RoI Pooling层，得到7×7大小的特征图；

4.这些特征图展平，经过一系列全连接层得到预测结果：类别和边界框。

### RPN

比起前两者使用选择性搜索算法得到候选区域，Faster RCNN中，训练了一个RPN网络，来得到推荐区域。

![image-20210708190235308](__md__/image-20210708190235308.png)

+ 滑动窗口大小为3×3，窗口中心点对应的anchor有3×3=9种；
+ 对于一张1000×600×3的图像，大约有60×40×9 (20K)个anchor，忽略跨越边界的anchor后，剩下约6K个anchor。由于RPN生成的候选框之间存在大量重叠，所以基于候选框的cls得分，使用非极大值抑制，IoU=0.7，这样每张图就剩2K个候选框；
+ cls: 0或者1，coordinates: (x,y,w,h)。

### 训练

Faster RCNN的训练是直接采用RPN Loss + Fast RCNN Loss的联合训练方式。

1. 利用ImageNet预训练分类模型的权重，初始化backbone网络，然后开始单独训练RPN网络；

2. 固定RPN网络参数，训练bockbone和RoI Pooling组成的fast RCNN网络；
3. 固定Fast RCNN网络权重，训练RPN网络；
4. 固定backbone网络权重，微调Fast RCNN网络，来训练最后的几层全连接层；
5. 最后，RPN网络和fast rcnn网络，共享backbone，构成统一的网络。

以上。



