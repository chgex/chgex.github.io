---
layout: post
title: AlexNet
date: 2021-03-18
Author: JIUGE 
tags: [论文阅读]
comments: true
toc: false
---

该论文发布于2012年，对于深层卷积神经网络具有很重要的意义。

<!--more -->

# 论文简读：ImageNet Classification with Deep Convolutional Neural Networks

论文信息：

![image-20210318225544235](https://gitee.com/changyv/md-pic/raw/master/20210318225556.png)

论文链接：https://papers.nips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf

发表时间：2012年，于IEEE

## Abstract

作者提出了一个卷积神经网络，用以将ImageNet LSVRC-2010大赛中的120万幅高分辨率图像分为1000个不同的类别，该网络在测试集上的误差为37.1%，为当时最优（2010年）。

该网络拥有6000万个参数和65000个神经元。网络由5个卷积层组成，部分卷积层后面跟一个最大池化层。

为了减少全连接层的过拟合，作者用了丢弃法(Dropout)，该方法效果显著。

## 1 Introduction

当前（2010年）的目标检测方法主要使用的是机器学习的方法，为了提高目标检测方法的性能，需要更大的数据集，来学习更强大的模型。直到最近，才出现新的更大的数据集：ImageNet、LabelMe等。

卷积神经网络(Convolutional neural networks
, CNN)构成的模型，通过改变深度和宽度，可以很好的控制模型，而且，卷积神经网络对统计平稳性和像素局部依赖有很好的相关性(stationarity of statistics and locality of pixel dependencies)。相比于标准的前馈型神经网络( standard feedforward neural networks)，卷积神经网络拥有更少的参数和连接，更加易于训练。

这篇论文贡献如下：

+ 训练了一个大型卷积神经网络，在ImageNet的ILSVRC-2010 and ILSVRC-2012比赛上表现为最优，
+ 编写了一个高度优化的2D卷积的GPU实现，

> 作者当时可用的GPU的容量只有3G.

+ 使用dropout防止过拟合，
+ 模型包含5个卷积层和3个全连接层。

作者认为，网络大小受限于可用的GPU和训练时间（作者是在GTX 580 3GB GPU上训练的，一次训练需要6-7天），即算力大小限制了模型。

## 2 The Dataset

ImageNet数据集拥有1500多万张已标记的高分辨率图像，有大约22000个类别。

ImageNet数据集的图像分辨率不一，但模型的输入维数使恒定的，所以，作者将图像降采样到256\*  256的固定分辨率。

> 关于降采样：
>
> 对于给定的矩形图像，进行图像缩放，使较短的边为256，然乎从图像中心，裁剪出256\*256的图像块。
>
> 除了图像剪裁，作者没有使用其它的预处理方法。

## 3 The Architecture

模型一共8层：5个卷积层，3个全连接层。结构如下图：

<img src="https://gitee.com/changyv/md-pic/raw/master/20210318205610.png" alt="image-20210318205558381" style="zoom:75%;" />

> 从第一个卷积层开始，由2个GPU分别负责计算，一个负责图上端部分的卷积，另一个负责图下端部分的卷积。2个GPU只在特定的层中进行通信。
>
> 网络的输入为235\*225。

### 3.1 RELU Nonlinearity

作者搭建了一个4层的卷积神经网络，在CIFAR-10数据集上，分别使用不同的激活函数：ReLU和tanh，进行训练。epoch和training error rate的变化关系如下：

![image-20210318213838990](https://gitee.com/changyv/md-pic/raw/master/20210318213843.png)

实线(solid line)表示使用了ReLU激活函数的训练误差变化，虚线(dashed line)表示使用了tanh激活函数的训练误差变化。两者达到0.25训练误差所需的的时间，相差6倍多。

所以，作者使用ReLU作为模型的激活函数。

### 3.2 Training on Multiple GPUs

单一GTX 580显卡的显存只有3GB，对于120万个样本的模型训练，是不够的。作者使用了2块并行GPU，它们可以直接互相读取数据，可不用经过CPU。

3.3 Local Response Normalization

跳过。

### 3.4 Overlapping Pooling

卷积神经网络中的池化层，汇总了相同卷积核的相邻神经元的输出（根据网络结构图，最大池化层汇总了2块GPU的卷积层输出结果）。卷积层参数stride=2，kernel_size=3，

> 如果strde=kernel_size, 获得的是局部池化，
>
> 如果stride<kernel_size, 得到的是重叠池化

作者发现，训练过程中，使用重叠池化的模型，不容易过拟合。

### 3.5 Overall Architecture

卷积神经网络的结构为：

+ 网络一个有8层，第一到第五层是卷积层，最后三层是全连接层，
+ 最后一层全连接层的后面，紧接softmax单元，
+ 第二，第四，第五层的卷积核，只与前一层中处于同一GPU的卷积层相连，
+ 第三层的卷积核，连接了第二层所有的卷积输出（即连接了2个GPU的卷积输出）。
+ response normalization层，跟在第一层和第二层的后面，
+ 最大池化层，跟在response normalization层和第五个卷积层的后面，
+ ReLU跟在每个卷积层和全连接的输出后面。

关于参数：

+ 第一层：

  + input image: 224\*224\*3
  + kernel_size: 11\*11\*3, stride=4

+ 第二层：

  + kernel_size=5\*5\*48,  256个，

+ 第三层：

  + kernel_size: 3\*3\*256, 384个，

+ 第四层：

  + kernel_size: 3\*3\*192,  384个

  第五层：

  + kernel_size: 3\*3\*192,  256个。

+ 每个全连接层都有4096个神经元。

## 4 Reducing Overfitting

为了处理过拟合，作者使用了以下方法：

1.数据增强(Data Augmentation)：

+ 使用了两种图像变换方法：图像平移、水平反射。
+ 改变训练图像的RGB通道的强度：对整个ImageNet数据集使用PCA（主成分分析法）。

2. Dropout

作者在第一、第二个全连接层使用了dropout。

## 6 Result

在ILSVRC-2010上，模型的表现如表1：

<img src="https://gitee.com/changyv/md-pic/raw/master/20210318223619.png" alt="image-20210318223616995" style="zoom:50%;" />

在ILSVRC-2012上的表现如表2所示：

<img src="https://gitee.com/changyv/md-pic/raw/master/20210318223730.png" alt="image-20210318223728963" style="zoom:50%;" />

7 Discussion

+ 实验结果表明，一个大的，深的卷积神经网络能够在高挑战性的数据集上获得突破性的结果。

+ 作者在实验中，由于算力所限，所以没有使用任何预训练。

## 总结

1. AlexNet网络使用5个卷积层和3个全连接层。
2. 网络中的全连接层，使用了dropout，防止过拟合。

基于pytorch的AlexNet模型代码实现：

数据集使用的是fashion_mnist，所以输出类别需要调整为10。

```python
import torch
from torch import nn,optim
import torchvision
import time

device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')

num_classes=10
class AlexNet(nn.Module):
    def __init__(self):
        super(AlexNet,self).__init__()
        self.conv=nn.Sequential(
            # layer 1
            nn.Conv2d(in_channels=3,out_channels=96,kernel_size=11,stride=4),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=3,stride=2),
            # layer 2
            nn.Conv2d(in_channels=96,out_channels=256,kernel_size=5,groups=2,padding=2),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=3,stride=2),
            # layer 3
            nn.Conv2d(in_channels=256,out_channels=384,kernel_size=3,padding=1),
            nn.ReLU(inplace=True),
            # layer 4
            nn.Conv2d(in_channels=384,out_channels=384,kernel_size=3,padding=1),
            nn.ReLU(inplace=True),
            # layer 5
            nn.Conv2d(in_channels=384,out_channels=256,kernel_size=3,padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=3,stride=2)
        )
        self.fc=nn.Sequential(
            # layer 6
            nn.Linear(in_features=6*6*256,out_features=4096),
            nn.ReLU(inplace=True),
            nn.Dropout(0.5),
            # layer 7
            nn.Linear(in_features=4096,out_features=4096),
            nn.ReLU(inplace=True),
            nn.Dropout(0.5),
            # layer 8
            nn.Linear(in_features=4096,out_features=num_classes)
        )
    def forward(self,img):
            feature=self.conv(img)
            # output=self.fc(feature.view(img.shape[0],-1))
            output=self.fc(feature.view(-1,6*6*256))
            return output
        
# print net
net=AlexNet()
print(net)



# 图像预处理
# 构建一个列表：将多个图像变换实例集合到一起
resize=227
from torchvision import transforms
transform = transforms.Compose([
    transforms.Resize(size=resize),
    transforms.ToTensor(),
  	# Normalize 这8个值是针对 CIFAR-10 这个数据集算出来的，对于其他数据集不适用
    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))
])

# 加载数据集
# CIFAR10 dataset
train_dataset = torchvision.datasets.CIFAR10(
    root='../datasets/', 
    train=True, 
    download=False, 
    transform=transform)

test_dataset= torchvision.datasets.CIFAR10(
    root='../datasets/', 
    train=False,
    download=False, 
    transform=transform)

batch_size=128

# data loader
train_iter=torch.utils.data.DataLoader(
    train_dataset, 
    batch_size=batch_size, 
    shuffle=True, 
    num_workers=4)
test_iter=torch.utils.data.DataLoader(
    test_dataset, 
    batch_size=batch_size, 
    shuffle=False, 
    num_workers=4)

def evaluate_accuracy(data_iter,net,device=None):
    # gpu
    if device is None and isinstance(net,torch.nn.Module):
        # 如果没有指定device，则使用net的device
        device=list(net.parameters())[0].device
    # 准确率，总数
    acc_sum,n=0.0,0
    # with torch.no_grad： disables tracking of gradients in autograd. 
    # model.eval()： changes the forward() behaviour of the module it is called upon.
    with torch.no_grad():
        for X,y in data_iter:
            if isinstance(net,torch.nn.Module):
                # 评估模式，该模式会关闭dropout
                net.eval()
                # torch.argmax(input, dim, keepdim=False) → LongTensor返回指定维度的最大值的索引。
                acc_sum+=( net(X.to(device)).argmax(dim=1) == y.to(device) ).float().sum().cpu().item()
            else: # 无GPU
                if('is_training' in net.__code__.co_varnames): # 如果有is_training这个参数
                    # 将is_training设置成False
                    acc_sum += (net(X, is_training=False).argmax(dim=1) == y).float().sum().item() 
                else:
                    acc_sum += (net(X).argmax(dim=1) == y).float().sum().item() 
            n+=y.shape[0]
    return acc_sum/n

def train(net,train_iter,test_iter,batch_size,optimizer,device,num_epochs):
    net=net.to(device)
    print('training on ',device)
    # 损失函数，使用交叉熵损失函数
    loss=torch.nn.CrossEntropyLoss()
    
    for epoch in range(num_epochs):
        train_l_sum,train_acc_sum,n,batch_count,start=0.0,0.0,0,0,time.time()
        for i,(X,y) in enumerate(train_iter):
            X=X.to(device)
            y=y.to(device)
            y_hat=net(X)
            # 计算损失
            l=loss(y_hat,y)
            # 梯度清零
            optimizer.zero_grad()
            # 反向传播
            l.backward()
            # 更新参数
            optimizer.step()
            
            print('epoch %d/%d, iter %d/391, loss %.3f' % (epoch,num_epochs,i,l.cpu().item()))


            # 更新损失和正确率
            train_l_sum+=l.cpu().item()
            train_acc_sum+=(y_hat.argmax(dim=1) == y ).sum().cpu().item()
            n+=y.shape[0]
            batch_count+=1
        # 测试集上的正确率
        test_acc=evaluate_accuracy(test_iter,net)
        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec'
        %(epoch+1,train_l_sum/batch_count,train_acc_sum/n,test_acc,time.time()-start))    

        
# hyperparameters
# learning rate, epoch
lr,num_epochs=0.001,1
# optimizer
optimizer=torch.optim.Adam(net.parameters(),lr=lr)


# training
train(net,train_iter,test_iter,batch_size,optimizer,device,num_epochs)



```



