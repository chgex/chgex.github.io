---
layout: post
title: Fast R-CNN
date: 2021-04-06
Author: liu_bai 
tags: [论文阅读]
comments: true
toc: false
---

这篇论文发表于2014年，提出RoI池化层，解决了R-CNN推荐区域特征图重复计算的问题。

<!-- more -->

# Fast R-CNN

论文信息：

<img src="D:%5Cblog%5Cphoto%5Cimage-20210406142154238.png" alt="image-20210406142154238" style="zoom:33%;" />

发表时间：2014年，于CVPR

[论文链接](https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Girshick_Fast_R-CNN_ICCV_2015_paper.pdf)



## Abstruct

Fast R-CNN全名Fadst Region-based Convolutional Network。使用深层卷积神经网络分类候选目标。与R-CNN相比，训练VGG-16网络，Fast R-CNN训练时间快9倍，测试时间快213倍。与SPPNet相比，训练时间快9倍，测试时间快10倍。Fast R-CNN在PASCAL VOC 2012上实现了很高的准确率：66%（vs R-CNN是62%）。

## 1 Introduction

作者指出R-CNN一些缺点：

1. R-CNN的训练分为多个阶段：

   + 训练卷积网络，提取候选区域的特征向量，
   + 训练SVM，取代softmax分类器，
   + 训练边界框回归器。

   保存候选区域的特征向量，并用于训练SVM，将占用极大内存，而且训练一次需要2.5天。

2. R-CNN检测速度慢。网络处理依次每个候选区域，但大部分候选区域是重叠的，所以重复计算。

SPPNet只在候选区域计算上有所改进：共享候选区域计算。但其它部分基本无改进。

作者提出的fast R-CNN，具有以下优点：

1. 高检测精度（mAP）,
2. 训练是单阶段的，使用多任务损失(multi-task loss)
3. 训练时，可以更新所有的网络层，
4. 不需要进行特征向量缓存，所以不需要额外空间。

题外话：

+ fast rcnn还是使用基于相似度计算规则的选择性搜索算法来生成候选区域，而不是通过学习，
+ region proposals、proposal location、object proposal、region of interst 描述的都是同一个东西，这里使用“候选区域”来描述。

## 2 Fast R-CNN architecture and training

 Fast R-CNN结构如下：

<img src="D:%5Cblog%5Cphoto%5Cimage-20210403192757621.png" alt="image-20210403192757621" style="zoom:50%;" />

fast r-cnn网络：

+ 以整张图和候选区域集作为网络输入，
+ 卷积层和最大池化层，处理整张图片，产生卷积特征图
+ ROI池化层(region of interst, ROI)：处理每个候选区域，从卷积特征图中，提取出特定长度的特征向量，
+ 全连接层：将所有的特征向量，输入到一系列全连接层。并将输出，输入到两个平行分支：
  + 分支一：输出K+1类的softmax的概率预测。（K个目标类别加1个背景类别）
  + 分支二：为每个候选区域，输出4个实数值，即边界框位置。

**2.1 The RoI pooling layer**

ROI池化层使用最大池化方式，将ROI(候选区域)转换为尺寸为H\*W的小特征图，比如7\*7，(H和W是超参数)。

每个候选区域，被定义为四元组：(r,c,h,w)，分别表示矩形左上角坐标和矩阵高宽。

ROI池化层工作过程：

+ 将h\*w的ROI，分为H\*W的网格，每个网格为$\frac{h}{H} *\frac{w}{W}$ 大小。
+ 使用最大池化，处理每个网格单元（即max-pooling 每个网格单元，每个网格单元输出一个最大值），得到 $H *W$ 的特征图。
+ 从特征图中提取固定长度的特征向量，作为下一层：全连接层的输入。

**2.2 Initializing from pre-trained network**

fast rcnn网络结构：

1. 使用ROI最大池化层代替网络最后一层池化层，VGG16网络中，ROI池化层的H=W=7
2. 使用两个并行层，代替网络最后的全连接层和softmax。
3. 网络接受两个输入：图片和图片中ROI的映射（projection）

**2.3 Fine-tuning for detection**

fast renn可以使用反向传播，以训练整个网络的权重参数。

 作者提出一个有效的训练方法：共享特征。在R-CNN中，随机梯度下降(stochastic gradient descent, SGD)，小批量(mini-batch)，是分阶段进行的。一次采样N张图片，每张图片采样R/N个ROI，比如N=2，R=128，这样的训练方式比从128张图片中个各采样一个ROI，训练速度更快，因为前者可以共享ROI的计算。

**multi-task loss**

 Fast R-CNN网络有2个平行分支：

1. 分支一：输出每个ROI的类别向量 $p=\{p_0,p_1,...p_k\} $ ，一共有K+1类。

2. 分支二：输出边界框回归坐标（bounding box regression ofset）$t_k=(t_x^k,t_y^k,t_w^k,t_h^k)$ ，其中k表示第k个类别的物体。论文中对于$t_k$的描述：

   > $t_k$ specifies a scale-invariant translation and log-space height/width shift relative to an object proposal.

 每个ROI，对应的ground truth class为u，ground truth bounding box为v，于是损失多任务损失函数定义为：
$$
L(p,u,t^u,v)=L_{cls}(p,u) + \lambda[u \geq 1]L_{loc}(t^u,v)
\tag{1}
$$
其中：

+ 分类损失$L_{cls}(p,u)=-log(p_u)$ ，即对真实类别u的log损失。

+ 边界框回归损失$L_{loc}(t^u,v)$ ，类别u真值边界框$v=(v_x,v_y,v_w,v_h)$  ，类别u预测边界框$t_u=(t_x^u,t_y^u,t_w^u,t_h^u)$ 。详细定义在下面。

+ $[u \geq 1]$ 表示：当类别u大于等于1的时候，$[u \geq 1]$ 值为1，如果类别u等于0，$[u \geq 1]$ 值为0。因为背景类别u=0，不需要回归背景边界框。

在反向传播的过程中，$L_{loc}$会被省略。

$L_{loc}$定义如下：
$$
L_{loc}(t^u,v)=\sum_{i \in {x,y,w,h}} smooth_{L_1}(t_i^u-v_i),
\tag{2}
$$
其中：
$$
smooth_{L_1}(x)=
\begin{cases}
0.5x_2  \;\;\;\;\;\; if|x|<1\\
|x|-0.5 \;\; otherwise
\end{cases}
\tag{3}
$$

+ $\lambda$ 是超参数，用于平衡分类损失和回归损失。作者在实验中，该值为1.

**mini-batch sampling**

小批量采用N=2，R=128。即一次输入两张图片，每张图片采样64个ROI。

使用启发式的难样本挖掘。

仅使用了概率为0.5的图像水平翻转这一个数据增强，

**Back-propagation through ROI pooling layers**

假设N=1，令$x_i\in R$ 表示输入到ROI池化层的输入的第i个激活，令$y_{rj}$ 表示第r个ROI的第j个输出。于是ROI池化层计算过程为：
$$
y_{rj}=x_{i * (r,j)}
$$
其中：
$$
i*(r,j)=argmax \;x_{i'},\;i'\in R(r,j)
$$
$R(i,j)$ 为输入的下标号

ROI池化层反向传播：对于输入的$x_i$ ,损失函数的偏导数求导如下：
$$
\frac{\partial L}{\partial x_i}=\sum_i \sum_j [i=i*(r,j)] \frac{\partial L}{\partial y_{rj}}
\tag{4}
$$
对于每个小批量ROI：r，和每个池化输出单元$y_{rj}$ ，偏导数$\partial L / \partial y_{rj}$。

> 看完代码之后，再回来补充。。

**SGD 超参数**

全连接层使用softmax函数分类，边界框回归全连接层参数初始化为：分别使用均方差（standard deviations）为0.01和0.001的高斯分布进行初始化。偏差为0.

初始学习率为0.001，动量为0.9，decay为0.00005.

**2.4 Scale invariance**

作者分别使用两种方式，确保目标检测的尺寸不变性：

+ 通过蛮力（brute force）：每张图片被处理为固定像素大小。
+ 通过图像金字塔。

## 3 Fast R-CNN detetcion

作者使用truncated SVD技术处理全连接层参数矩阵，以加快目标检测时全连接层的计算速度。原理如下：

对于参数矩阵$W_{u*v}$ ，使用SVD分解，可以将W的参数规模从 $u*v$ 缩小到$t*(u+v),\;t <<min(u,v)$ 。

SVD矩阵分解式如下：
$$
W=U_{u×t}\Sigma_{t×t}V_{v×t}^T
\tag{5}
$$
使用SVD分解之后，一个全连接层，将被分解为2个全连接层：第一个全连接层权重为$\Sigma V^T$ ，无偏差。第二个全连接层参数为$U$ ，使用原全连接层的参数。

当ROI数量很大时，这种计算的加速方式，效果可观。

## 4 Main result

1. 在VOC 2007,2010,2012取得当时最好的mAP.
2. 比R-CNN，SPPNet训练时间更短。
3. 微调VGG-16网络的conv层，提高mAP.

接下来，就是一些实验和结果，此处跳过。